\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[toc,page]{appendix}
\usepackage{microtype}
\usepackage{fullpage}
\usepackage{multirow}
\usepackage{tocloft}

\usepackage{minted}
\setminted[]{linenos, numbersep=5pt, frame=lines}

\usepackage{parskip}
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}

\usepackage{array}
\newcolumntype{L}{>{\centering\arraybackslash}m{1.2in}}
\newcolumntype{M}{>{\centering\arraybackslash}m{0.85in}}

\usepackage[affil-it]{authblk}
\usepackage{amsfonts, amssymb, amsmath}

\usepackage{wrapfig}
\usepackage{graphicx}
\graphicspath{ {./images/} }

\usepackage{float}

\usepackage[backend=biber]{biblatex}
\addbibresource{sources.bib}
% Use the followign Command to validate *.bib file: biber --tool --validate-datamodel qualifying_exam_paper.bib

\title{Improving Emotion Detection through Real-Time Translation of Text to ML Models Trained in Different Languages}

\author{Richard Hoehn%
	\thanks{Electronic address: \texttt{rhoehn@mtmail.mtsu.edu}; corresponding author}}
\affil{Middle Tennessee State University}

\author{Dr. Jaishree Ranganathan%
	\thanks{Electronic address: \texttt{jaishree.ranganathan@mtsu.edu}}}
\affil{Middle Tennessee State University}

\begin{document}

\maketitle

\begin{abstract}
This Qualifying Exam\footnote{PhD students of MTSU Computational and Data Science program are required to complete a Qualifying Exam in their first year in the program.} research paper investigates the potential of improving Emotion Detection (ED) through real-time translation of text to multiple Machine Learning (ML) models trained in different languages specifically  English and German. The research aims to address the challenges posed by the lack of comprehensive labeled datasets and language fragmentation in ED analysis research and projects. 

By extending an original English language dataset with a translated dataset from German to English the training data (extended dataset) the hope is that better prediction rates can be achieved in ED analysis applications. Furthermore, translating English to German to extend the German dataset and training another ML model in parallel using PySpark and accessing both models in real-time by a simple RESTful API may improve the prediction rates by dual processing a sentence at the same time.

In order to present the results presented both orally to the MTSU's Computational Data \& Science Committee and within this paper labeled datasets both in English and German were collected, translated, and two ML models built that can be accessed via an API to get a prediction on an input (POST or GET) sentence both in German or English.
\end{abstract}
\clearpage

\tableofcontents

\clearpage
\section{Introduction}

Emotion detection has gained significant interest in recent years as a means to understand human behavior and improve communication effectiveness. By analyzing text or speech, these detection processes can accurately identify and classify emotions expressed by individuals or groups, often times in real-time.

By employing a variety of ED processes, including natural language processing and machine learning, applications can detect emotions with high precision. These ED systems find applications in diverse fields, such as sentiment analysis, customer feedback analysis, voting and news stances, and mental health monitoring, which all aim at contributing to a deeper understanding of human emotions and their impact on various aspects of life.

\subsection{Human Emotion as a Theoretical Framework}

The concept and number of emotions can vary depending on the theoretical framework or model being considered. One well-known model is the Plutchik's Wheel of Emotions Figure \ref{fig:plutchik-wheel}, which proposes eight (8) primary emotions and their contrasting pairs. In this paper we will be focusing on the basic eight emotions and not on their sub-emotions.

Below are the eight primary emotions according to the Plutchik's Wheel of Emotions \cite{Tromp}, a detailed reference of emotions used in this research can be found in Table \ref{table:dataset_labels} on page~\pageref{table:dataset_labels}.

\begin{itemize}
\item Happiness: A feeling of Joy (Fun), contentment, or delight.
\item Sadness: A state of unhappiness, sorrow, or grief.
\item Anger: An intense emotional response associated with feelings of displeasure, frustration, or hostility.
\item Worry: An emotional response triggered by perceived threats or danger, often associated with anxiety or terror.
\item Surprise: A sudden and unexpected reaction to something unusual or startling.
\item Disgust and/or Hate: A strong aversion or revulsion towards something unpleasant, offensive, or repulsive.
\item Trust and/or Love: A sense of reliance, confidence, or faith in someone or something.
\item Enthusiasm: A feeling of excited expectation or eagerness towards future events.
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{Plutchik-Wheel}
    \caption{Plutchik Wheel of Emotions}
    \label{fig:plutchik-wheel}
\end{figure}

It's important to note that emotions are complex and multifaceted, and different models may propose alternative categorizations or variations in the number of primary emotions. However for the scope of this research project the most common eight (8) emotions are used as described above.

By aligning the emotional labels across the English \cite{english-dataset-twitter} and German \cite{german-dataset-cheese} datasets being used in this research all eight listed above were used. Details on the linkage of the two datasets is described in Section \ref{sec:data-procurement-process} with an emphasis on the Table \ref{table:dataset_labels}'s cross reference on page~\pageref{table:dataset_labels}.

\subsection{Significance of Emotion Detection (ED) in Machine Learning}
Emotion Detection (ED) analysis in Machine Learning (ML) models has gained significant attention due to its potential applications in various fields, including customer sentiment analysis, stance detection in regard to a specific targets such as news and voting\cite{mascarell-etal-2021-stance}, mental health monitoring\cite{Colonnello}, and human-computer interactions (chatbots\cite{chatbot-cognitive-awareness}) to just name a few.

By accurately identifying and understanding emotions from text data, ML applications can assist in improving user experiences, decision-making processes, and overall human-machine interactions in a positive manner\cite{Colonnello, mascarell-etal-2021-stance}. As an example, the primary goals of chatbots are entertainment, social contact, and novelty interaction, with a strong emphasis on productivity, scale-ability and cost reductions. In chatbots, there has been a immense requirement to simulate human-like characteristics and behavior during human-machine interactions\cite{emotion-detection-literature-review}. Per Kusal et al. \cite{chatbot-cognitive-awareness} these chatbots also improve customer engagement by offering friendliness, comfortness, flexibility, and efficient assistance. Chatbots should provide customers with more engaging responses, directly addressing their issues. The goal of deploying ED applications is for users perceive chatbots as companions rather than simple assistants. Per Adikari et al. the majority of user requests are emotional rather than informative. Chatbots gained the capacity to respond emotionally to customers due to machine learning and sentiment analysis evolution\cite{chatbot-cognitive-awareness}.

\begin{quote}
    I usually know almost exactly how I feel. The problem is, I just can’t tell anyone.
    \flushright -- Meg Cabot
\end{quote}

Due to the before mentioned wide scope of uses for ED this field of research and the work to advance it provides significance and importance in enabling machines to comprehend and respond appropriately to human interactions. This in turn contributes to the advancement of artificial intelligence, natural language processing and in many cases the utilization of text-to-speech applications most all of us in today's society use and rely on \cite{ai-framework-detection-emotions}.

Lastly, in Chen et al.\cite{research-emotion-recognition-for-online-learning} paper based on emotion detection for online learning, it states that with emotion recognition research, we need to focus on accuracy and real-time performance in order to apply emotional recognition based on physiological signals to solve practical problems; they key part of their claim is that in order for ED to be practical real-time methods needs to be used.

\subsection{ED challenges: Lack of Labeled Datasets and Language Fragmentation}
ED is an immensely growing field, however unlike Sentiment Analysis (SA) the availability of large datasets for training purposes of ML models is much smaller \cite{ACLU-ED-Data, ai-framework-detection-emotions}. The primary reason of the lack of data stems from the emotion detection data requiring primarily supervised learning dataset, which require time and effort to procure, and mostly created and labeled by humans. To compound on the issue of the lack of data; the many datasets that are available are in multiple languages. A significant amount of time took place to find the German labeled 

\subsection{Motivation for the research project focusing on extending ED datasets through translation and evaluating the impact on prediction rates}

This paper is significant because an entire industry of automated emotion reading (Text, Image, Video, and Sound) technologies is quickly emerging \cite{ACLU-ED-Data, ACLU-THE-DAWN-OF-ROBOT-SURVEILLANCE}. The market for emotion recognition software is forecast to reach at least \$3.8 billion by 2025 \cite{ACLU-ED-Data, ACLU-THE-DAWN-OF-ROBOT-SURVEILLANCE}. And since ED is already being incorporated into products for purposes such as marketing, robotics, driver safety, customer service and a multiple of others, it is fitting to work on research to solve issues with prediction rates and lack of teaching / learning data.

With the before mentioned issues regarding the quantity (lack of) and fragmentation of the ED datasets this research was motivated by finding a way to combine different language datasets into a single set for training processes to improve the predictability of ED. The hope is that by use of translation that the predictability of ED can be improved by use of real-time language conversion and processing.

\subsection{Objectives \& Scope of the Research}

The research project aims at answering the following research questions:

\begin{itemize}
\item Can by translating English data to German and extending an original German dataset increase the predictability of the ED model?
\item Can by translating German data to English and extending an original English dataset increase the predictability of the ED model?
\item Can by translating in real-time an input to multiple languages improve the predictability based on the combined output of two model's results.
\end{itemize}

\clearpage
\section{Literature Review}
To ensure comprehensive coverage of the latest developments and research in emotion detection and analysis for this research paper, consideration and review was only given to incorporating research papers and online news articles that were published after the year 2015, thereby providing an up-to-date perspective on the subject matter. By implementing the 2015 boundary, our methodology aims to provide a more up-to-date outlook on the subject matter at hand and what areas the ED field in moving in in respect to ML applications and processes.

\subsection{Emotion Detection Importance and Diverse Populations}
Emotion Detection (ED) holds significant importance in various domains, including psychology, social sciences, and human-computer interaction. It enables the analysis of human emotions at scale, providing valuable insights into individual and collective emotional states. In Chowanda et. al. paper\cite{CHOWANDA-2021821} they believe that "Emotions hold a paramount role in the conversation, as it expresses context to the conversation."

Furthermore, emotions can differ across age groups, genders, cultures, and languages. Including data from diverse populations helps in developing inclusive and culturally sensitive ED models. It ensures that the models are not biased towards specific groups and can accurately detect emotions in a wide range of individuals.

\subsection{Lack of Labeled Datasets and Fragmentation caused by Different Languages}

The lack of diverse and large-scale data hinders the development and training of accurate ED models, limiting their effectiveness and general ability across different contexts and populations.

In recent research, efforts have been made to address these limitations by exploring new techniques for emotion detection. For instance, a study by Kapoor\cite{KAPOOR2023120882} et al. proposes analyzing the entire spectrum of the language source to predict emotional changes. This provided some help, but quickly established itself as time consuming and need of expertise in the subject matters. Overcoming the scarcity of labeled datasets and embracing innovative approaches like the before mentioned study by Kapoor\cite{KAPOOR2023120882} et al. and their analysis can contribute to the advancement of ED research. Such advancements hold the potential to enhance the accuracy and applicability of emotion detection models, enabling a deeper understanding of human emotions and more effective responses in various domains.

The paper by Mascarell\cite{mascarell-etal-2021-stance} et al. states that unlike images language operate very differently, therefore the lack of labeled datasets poses a significant challenge in text-based Emotion Detection (ED) analysis as it limits the availability of reliable training data for ML models. This scarcity hampers the model's ability to learn and generalize emotions effectively.

Additionally, Kusal et al. further stipulates \cite{kusal} that the fragmentation caused by different languages further exacerbates the issue, as it reduces the size and diversity of data available for training, resulting in limited cross-lingual generalization and potentially biased models. Overcoming these challenges is crucial for advancing ED research and improving the accuracy and applicability of emotion detection models across various languages and cultures.

\clearpage
\section{Methodology}

\subsection{Data procurement process of ED datasets in English and German}
\label{sec:data-procurement-process}
The data procurement was relatively straight forward and in essence entailed using Google search terms for the Emotion Detection in English and German. Some of the main German data was obtained from the dataset built by ETH's Emotion and Stance Detection for German Text \cite{mascarell-etal-2021-stance} which also hosts a good website with their findings \footnote{https://mtc.ethz.ch/research/natural-language-processing/emotion-stance.html}. The English dataset was downloaded from Kaggle \footnote{https://www.kaggle.com/datasets/pashupatigupta/emotion-detection-from-text} based on Tweets collected in 2021. The English dataset contains over 38,000 tweets and their corresponding emotion labeled. Similarly the German contains over 12,000 sentences and their respective emotions associated.

An important part of the process is to make sure we match the English emotions to those of the German language emotions. Since the tow languages are dissimilar we opted to match exact emotions to each other that can be seen in Table \ref{table:dataset_labels} below.

\begin{table}[h!]
\centering
\begin{tabular}{ | c c | c c | c | }
    \hline
    \multicolumn{5}{|c|}{Emotion Datasets Labels} \\
    
    \hline
    \multicolumn{2}{|c|}{English} & \multicolumn{2}{|c|}{German} & \multirow{2}{*}{Used} \\
    Name & Count & Name & Count \\
    \hline
    Boredom    &  179 & ---           & --- & NO  \\
    Love       & 3842 & Vertrauen     & 316 & YES \\
    Relief     & 1526 & ---           & --- & NO  \\ 
    Fun        & 1776 & ---           & --- & NO  \\
    Hate       & 1323 & Ekel          &  29 & YES \\
    Neutral    & 8638 & Unklar        & 314 & YES \\
    Anger      &  110 & Ärger         & 226 & YES \\
    Happiness  & 5209 & Freude        & 140 & YES \\
    Surprise   & 2187 & Überraschung  & 369 & YES \\
    Sadness    & 5165 & Traurigkeit   & 184 & YES \\
    Worry      & 8459 & Angst         & 154 & YES \\
    Enthusiasm &  759 & Antizipation  & 774 & YES \\
    Empty      &  827 & ---           & --- & NO  \\
    \hline
\end{tabular}
\caption{Dataset of English \& German and their respective label counts.}
\label{table:dataset_labels}
\end{table}

Details on how we formatted the the two (English and German) datasets to each other can be viewed in the Appendix \ref{appendix:dataset_english} and \ref{appendix:dataset_german}

The procurement of two ED datasets is needed. The first will be in English and the second in German. Each dataset will be translated into the other’s language for extending purposes. As an example Figure \ref{fig:dataset-extension} depicts the original English dataset will be extended by the translated German dataset.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.35\textwidth]{Dataset-Extension}
    \caption{Example of English dataset extension by translating from German.}
    \label{fig:dataset-extension}
\end{figure}

The reason for selecting German was based on the author\footnote{Richard Hoehn} being fluent in English and German and hence being able to easily traverse the two languages while working on the code for dataset translations and formatting.

Once the two datasets have been translated, we now extend the original language dataset with the translated one.By this approach we are in essence extending the original datasets to create a larger one with the foreign language data. With both extended datasets we can now train our ML models for English and German.

\subsection{Development of a translation application for converting different languages into English and vice versa}
Translation of the emotion datasets was performed with Google Translator based on the Medium article\cite{Nidhaloff_how_to_translate_text_with_python} in which the author describes option for simple API translations. As an example the following is a brief introduction to Google Translator's API:

\begin{quote}
\begin{minted}[fontsize=\small]{python}
# Using Deep Translator to leveage Google Translate
# Link: https://cloud.google.com/translate/docs/reference/libraries/v2/python
from deep_translator import GoogleTranslator

sentence = 'Chocolate milk is so much better through a straw.'

translated = GoogleTranslator(source='auto', target='de').translate(sentence)
print(translated) # Schokoladenmilch schmeckt durch einen Strohhalm viel besser.

translated_back = GoogleTranslator(source='auto', target='en').translate(translated)
print(translated_back) # Chocolate milk tastes much better through a straw.
\end{minted}
\end{quote}

Based on the above example the CSV and JSON datasets were individually loaded, parsed, and translated to their respective counter-part languages. Details of the application can be found in the Appendix \ref{appendix:dataset_english} for English and Appendix \ref{appendix:dataset_german} for the German. We decided to only use 1,500 row for each language so since the German (DE\footnote{DE = German}) dataset was not much larger than that. This meant that the English (EN\footnote{EN = Enlgish}) datasets was randomly paired down to 1,500 to match that of the German.

Each translated file now contains four (4) columns that are labeled in Tables \ref{table:pd_de_translated} and \ref{table:pd_en_translated} with the exact same column naming.

\begin{table}[h!]
\centering
\begin{tabular}{ | L | L | L | L | }
    \hline
    \multicolumn{4}{|c|}{File: \texttt{pd\textunderscore de\textunderscore translated.csv}} \\
    \hline
    sentence\textunderscore de &
    emotion\textunderscore de & 
    sentence\textunderscore en & 
    emotion\textunderscore en \\
    \hline
    Original Sentence (feature) &
    Original Emotion (label) &
    Sentence Translated to English & 
    Emotion set by Cross-Reference from German \\

    \hline
\end{tabular}
\caption{German CSV file structure after translation to English}
\label{table:pd_de_translated}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{ | L | L | L | L | }
    \hline
    \multicolumn{4}{|c|}{File: \texttt{pd\textunderscore en\textunderscore translated.csv}} \\
    \hline
    sentence\textunderscore en &
    emotion\textunderscore en & 
    sentence\textunderscore de & 
    emotion\textunderscore de \\
    \hline
    Original Sentence (feature) &
    Original Emotion (label) &
    Sentence Translated to German & 
    Emotion set by Cross-Reference from English \\

    \hline
\end{tabular}
\caption{English CSV File structure after translation to German}
\label{table:pd_en_translated}
\end{table}

\subsection{Training Multiple ML models with PySpark}

 Using the datasets from Tables \ref{table:pd_de_translated}, \ref{table:pd_en_translated}, and \ref{table:ml_models} that list an approximate $\sim$1,275 and $\sim$2,775 features for training. The algorithms tested in this research project ranged from the traditional machine learning to deep learning techniques, they are:
 \begin{itemize}

\item \textbf{Na\"ive Bayes:} Per Pujan's paper\cite{naive-bayes-model} on the Na\"ive Bayes model, it classifies and/or assigns the most likely class to a given example based on its feature vector, simplifying the task greatly by assuming that the features are independent given a class. 

\item \textbf{Generalised Linear Model (GLM):} Per Mueller's paper on GLM\cite{glm-model} the Generalized linear models extend the concept of the well understood linear regression model.

\item \textbf{Random Forest Classifier:} Per Schonlau's paper\cite{random-forest-model} on the Random Forest Classifier, they state that random decision forests easily adapt to non-linearity found in the data and therefore tend to predict better than linear regression. More specifically, ensemble learning algorithms like random forests are well suited for medium to large datasets.

\end{itemize}
 
Each of these algorithms used and their results are listed in the Results and Analysis Section \ref{sec:results-and-analysis} below. In Chowanda et al. paper\cite{CHOWANDA-2021821} on Text-based Emotion Techniques multiple algorithms were proposed, this research focused on just three out of their six since the others had lower prediction rates based on Chowanda et al. paper\cite{CHOWANDA-2021821} paper.

 \begin{table}[h!]
\centering
\begin{tabular}{ | L | L | L | L | }
    \hline
    \multicolumn{4}{|c|}{ML Models } \\
    \hline
    Model & 
    Data &
    Rows for Training (85\%) & 
    Rows for Testing (15\%)  \\
    \hline
    A &
    English Original &
    1,275 & 
    225 \\
    \hline
    B &
    English Extended By German &
    2,775 & 
    225 same as Model "A" \\
    \hline
    C &
    German Original &
    1,275 & 
    225 \\
    \hline
    D &
    German Extended By English &
    2,775 & 
    225 same as Model "C" \\
    

    \hline
\end{tabular}
\caption{ML Models and their respective settings}
\label{table:ml_models}
\end{table}

In order for each of the three ML models to be processed at the same time we crated a Jupyter Notebook that starts an Apache PySpark\footnote{PySpark: https://spark.apache.org/docs/latest/api/python/index.html} session that is accessed via the local server running that accepts RESTful API calls with details of the server in Appendix \ref{appendix:code-api-server}.

\subsection{Evaluation Metrics and methodologies for measuring the performance of the ML models}
\label{sec:evaluation-metrics-and-methodologies}
The evaluation of ML models trained on the English, German and their respective extension datasets is a critical step in assessing their performance and reliability. We chose to use the MulticlassClassificationEvaluator\footnote{URL: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.MulticlassClassificationEvaluator.html} because is a well known tool in the field of natural language processing (NLP) research, specifically in multi class classification tasks such as emotion detection that has multiple labels associated with it; in our case eight (8) see Table \ref{table:dataset_labels} on Page \pageref{table:dataset_labels}. Generally this evaluator is used to evaluate the performance of machine learning (ML) models, using transformer-based architectures like BERT, RoBERTa, or DistilBERT\cite{Sanh2019-DistilBERT-AD}, with DistilBERT\cite{Sanh2019-DistilBERT-AD} being the one we used in this research project.

The MulticlassClassificationEvaluator provides the essential evaluation metrics, including accuracy, precision, recall, and F1 score, for ED classifications. These metrics provide valuable insights into a model's ability to correctly classify emotions across multiple classes and languages. Our research project is no different and the following measurements were used for our analysis:
\begin{itemize}

\item \textbf{Accuracy:} Accuracy measures the overall correctness of the emotion predictions made by the model. It is calculated as the ratio of correctly classified instances to the total number of instances in the dataset.

\item \textbf{F1 Score:} Precision represents the proportion of correctly predicted emotions among all instances predicted as a specific emotion with respect to the labels. Recall measures the proportion of correctly predicted emotions among all instances that truly belong to a specific emotion. With these two the F1 Score ($F_{1}=\frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$) combines precision and recall into a single metric, providing a balanced evaluation.

\end{itemize}

While evaluating the models we focused on the Accuracy and the F1 Score to illustrate the prediction results of the original versus extended datasets.

\subsection{Written \& Oral Presentation of Research Finding}
In conclusion of the project a research paper and oral presentation is required to pass MTSU Computation Science PhD Qualifying Exam. The listing the datasets used, code for the application, and details of the research project process in this research paper is openly available and hosted on a GitHub repository, allowing for easy access, reproducible, and collaborative engagement with the research findings. The repository is open and available under: \texttt{https://github.com/richardhoehn/mtsu.coms.qualifying-exam}\cite{Hoehn_Improving_Emotion_Detection_2023}

\clearpage
\section{Results and Analysis}
\label{sec:results-and-analysis}
The following section lists the prediction rates of training and testing of the original and extended datasets both in English and German. Overall results seem to indicate that there was no measurable benefit and even negative results based on adding the extended data for Emotion Detection. In the below sub sections details on the results are listed in prose, tables, and formulas.

\subsection{Prediction Results of Original \& Extended Datasets}
Overall the prediction results from the trained models is disappointing. Using the Random Forrest Classifier described in Section \ref{sec:evaluation-metrics-and-methodologies} provided the best prediction results based. Oddly, the prediction results with the extended data where lower than using the original (non-extended) data for training.

\subsubsection{English Dataset Results}
The Table \ref{table:en_testing_results} lists the results of all three ML models, their accuracy and F1 Score based on the English original and extended datasets. The improvements from the original and extended datasets are listed in the last column. In all cases the improvement to using the extended datasets was negative.

\begin{table}[h!]
\centering
\begin{tabular}{ | L | M | M | M | M | M | }
    \hline
    \multicolumn{6}{|c|}{Results of English Dataset} \\
    \hline
    &
    \multicolumn{2}{c|}{Original Dataset} &
    \multicolumn{3}{c|}{Extended Dataset} \\
    & Accuracy & F1 Score & Accuracy & F1 Score & Improvement \\
    \hline
    Random Forrest & 
    29.72\% &
    20.32\% & 
    28.77\%  &
    19.47\% &
    -3.20\% \\
    \hline
    Na\"ive Bayes & 
    5.66\% &
    6.92\% & 
    3.77\%  &
    4.11\% &
    -33.39\% \\
    \hline
    GLM & 
    25.94\% &
    25.92\% & 
    22.64\%  &
    23.25\% &
    -10.37\% \\
    \hline
\end{tabular}
\caption{Model Testing Results on English Dataset}
\label{table:en_testing_results}
\end{table}

\subsubsection{German Dataset Results}
The Table \ref{table:de_testing_results} lists the results of all three ML models, their accuracy and F1 Score based on the German original and translated from English to German extended datasets. The improvements from the original and extended datasets are listed in the last column. Interestingly the Randon Forrest Classifier was the only negative improvement whereas the GLM and Naive Bayes models had improvements. However it should be noted that the prediction rates are so low in the GLM and Naive Bayes that they should not really be considered improvements.

\begin{table}[h!]
\centering
\begin{tabular}{ | L | M | M | M | M | M | }
    \hline
    \multicolumn{6}{|c|}{Results of German Dataset} \\
    \hline
    &
    \multicolumn{2}{c|}{Original Dataset} &
    \multicolumn{3}{c|}{Extended Dataset} \\
    & Accuracy & F1 Score & Accuracy & F1 Score & Improvement \\
    \hline
    Random Forrest & 
    34.29\% &
    17.51\% & 
    18.57\%  &
    13.44\% &
    -45.84\% \\
    \hline
    Na\"ive Bayes & 
    4.29\% &
    4.31\% & 
    6.67\%  &
    4.21\% &
    +55.48\% \\
    \hline
    GLM & 
    11.90\% &
    12.57\% & 
    14.76\%  &
    15.88\% &
    +20.03\% \\
    \hline
\end{tabular}
\caption{Model Testing Results on German Dataset}
\label{table:de_testing_results}
\end{table}

The improvements on the accuracy are based on Equation \eqref{eq:improvement} listed below. It is a simple and straightforward way of comparing the Accuracy from the original trained dataset to the extended trained dataset for purposes of comparing the potential benefits of the translation.

\begin{equation}
Improvement(\%) = \dfrac{(Accuracy_{Ext} (\%) - Accuracy_{Org} (\%))}{Accuracy_{Org}(\%)}
\label{eq:improvement}
\end{equation}

Further

\subsection{Analysis of the impact of Extending Datasets by Translation}
While extending datasets for machine learning training can often improve\cite{Sarker2021} model performance, it's important to recognize that this approach has its limitations, especially in ML models that can reach a limit on training data. In our case, relying on translation services for dataset expansion might not consistently yield better results when extending the data from translated text. These services, in our case Google Translate\footnote{Google Cloud Translate URL: https://cloud.google.com/translate} can introduce errors or inaccuracies in translations especially in the context of emotions of a particular text, leading to noisy or incorrect training data. Consequently, the models may learn from erroneous information, which did negatively impact our models performance on the ED tasks.

\subsection{Findings and Implications for Improving Emotion Detection}


\subsection{Conclusion and Future Work}
It's crucial to ensure the quality and accuracy of extended data, especially when language translation is involved, to prevent introducing more noise than meaningful information into the training process. Although the research did not garner any significant improvements by translating the German to English as a means on extending the English dataset, it actually made it the prediction results worse.

Future work includes testing and translating different models by using different translation services. Using Google Cloud's translation service was adequate for this research, however there are certainly better translation services that are available but are based on paid subscriptions.

\clearpage
\section{Demonstration and Application}

\subsection{Description of the developed translation application for real-time text translation}
Details of the entire application can be found on the github repository \cite{Hoehn_Improving_Emotion_Detection_2023}.

\subsection{Showcase of the application's functionality and its integration with the Emotion Detection process}
\ldots

\subsection{Demonstration of the real-time processing of translated text and emotion detection using the ML models}
\ldots

\subsection{GIT Repository Details}
The listing the datasets used, code for the application, and details of the research project process in this research paper is openly available and hosted on a GitHub repository, allowing for easy access, reproducible, and collaborative engagement with the research findings. The repository is open and available under: \texttt{https://github.com/richardhoehn/mtsu.coms.qualifying-exam}\cite{Hoehn_Improving_Emotion_Detection_2023}
\clearpage


\addcontentsline{toc}{section}{References}
\printbibliography
\clearpage


\addcontentsline{toc}{section}{List of Figures}
\listoffigures
\clearpage


% Appendix Details
\appendix
\input{appendix/dataset} % Note: SubSection headers are handled within the *.tex file 
\input{appendix/code} % Note: SubSection headers are handled within the *.tex file 

\end{document}



