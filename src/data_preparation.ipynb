{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbe04a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark V:  3.3.2\n"
     ]
    }
   ],
   "source": [
    "# General Imports\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Setup Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Get Spark Functions Needed\n",
    "from pyspark.sql.functions import col, udf, split, explode\n",
    "\n",
    "# Get Datatypes needed for DataFrame manipulation\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "# Setup Spark Session\n",
    "sc = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"data_clean_up\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Print Spark Version being run\n",
    "print(\"Spark V: \", sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8312132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count (raw): 40000\n",
      "English Source Columns: ['tweet_id', 'sentiment', 'content']\n",
      "\n",
      "Count (filtered): 35692\n",
      "\n",
      "Grouped & Count by \"emotion\"\n",
      "+----------+-----+\n",
      "|emotion   |count|\n",
      "+----------+-----+\n",
      "|love      |3842 |\n",
      "|hate      |1323 |\n",
      "|neutral   |8638 |\n",
      "|anger     |110  |\n",
      "|happiness |5209 |\n",
      "|surprise  |2187 |\n",
      "|sadness   |5165 |\n",
      "|worry     |8459 |\n",
      "|enthusiasm|759  |\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./data/data_en.csv'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *********************************\n",
    "# *** English Data Preparations ***\n",
    "# *********************************\n",
    "\n",
    "# Load English CSV File into a Dataframe\n",
    "df_english = sc.read.csv(\"data/english.csv\", header=True, inferSchema=True)\n",
    "print(f'Count (raw): {df_english.count()}')\n",
    "\n",
    "# Print Columns\n",
    "print(f'English Source Columns: {df_english.columns}\\n')\n",
    "\n",
    "# Filter only lavbels that we mathc with the German counter parts\n",
    "filter_values = [\"love\", \"hate\", \"neutral\", \"anger\", \"happiness\", \"surprise\", \"sadness\", \"worry\", \"enthusiasm\"]\n",
    "df_english_filtered = df_english.filter(col(\"sentiment\").isin(filter_values))\n",
    "\n",
    "# Remove unnecessary column\n",
    "df_english_filtered = df_english_filtered.drop(\"tweet_id\")\n",
    "\n",
    "# Rename Columns\n",
    "df_english_filtered = df_english_filtered.withColumnRenamed(\"sentiment\", \"emotion\")\n",
    "df_english_filtered = df_english_filtered.withColumnRenamed(\"content\", \"sentence\")\n",
    "\n",
    "# Make sure the column order to the same for both german and english csv files\n",
    "df_english_filtered = df_english_filtered.select('sentence', 'emotion')\n",
    "\n",
    "print(f'Count (filtered): {df_english_filtered.count()}')\n",
    "\n",
    "# Group By for Details & Count\n",
    "df_english_grouped = df_english_filtered.groupBy('emotion').count()\n",
    "\n",
    "# Show Groupings and Respetive Counts\n",
    "print('\\nGrouped & Count by \"emotion\"')\n",
    "df_english_grouped.show(truncate=0)\n",
    "\n",
    "\n",
    "# Save Dataframe to CSV\n",
    "directory_path = 'data/spark_data_parts'\n",
    "df_english_filtered.coalesce(1).write.csv(directory_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "file_pattern = 'part-00000*.csv'\n",
    "file_path = glob.glob(directory_path + '/' + file_pattern)[0]\n",
    "\n",
    "shutil.move(file_path, './data/data_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec2eaf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count (raw): 1970\n",
      "German Source Columns: ['article_emotion', 'article_id', 'article_stance', 'paragraphs', 'snippet', 'source', 'title']\n",
      "\n",
      "Count (filtered): 2568\n",
      "\n",
      "Grouped & Count by \"emotion\"\n",
      "+------------+-----+\n",
      "|emotion     |count|\n",
      "+------------+-----+\n",
      "|Vertrauen   |316  |\n",
      "|Freude      |140  |\n",
      "|Ärger       |226  |\n",
      "|Überraschung|369  |\n",
      "|Traurigkeit |184  |\n",
      "|Antizipation|774  |\n",
      "|Unklar      |314  |\n",
      "|Angst       |154  |\n",
      "|Ekel        |29   |\n",
      "|Keine       |62   |\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./data/data_de.csv'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ********************************\n",
    "# *** German Data Preparations ***\n",
    "# ********************************\n",
    "\n",
    "# Load German JSON File into a Dataframe\n",
    "df_german = sc.read.json(\"data/german.json\")\n",
    "print(f'Count (raw): {df_german.count()}')\n",
    "\n",
    "# Print Columns\n",
    "print(f'German Source Columns: {df_german.columns}\\n')\n",
    "\n",
    "\n",
    "# We Need to \"split\" the \"artice_emotion\" column since the ETH team listed\n",
    "# multiple emotions in one column\n",
    "# In order to \"explode\" the column to it's distinct rows\n",
    "df_german_exploded = df_german.select('*', explode('article_emotion').alias('emotion'))\n",
    "\n",
    "# Rename Column\n",
    "df_german_exploded = df_german_exploded.withColumnRenamed(\"title\", \"sentence\")\n",
    "\n",
    "# Remove unnecessary column\n",
    "df_german_exploded = df_german_exploded.drop(\"article_id\")\n",
    "df_german_exploded = df_german_exploded.drop(\"article_stance\")\n",
    "df_german_exploded = df_german_exploded.drop(\"paragraphs\")\n",
    "df_german_exploded = df_german_exploded.drop(\"source\")\n",
    "df_german_exploded = df_german_exploded.drop(\"article_emotion\")\n",
    "df_german_exploded = df_german_exploded.drop(\"snippet\")\n",
    "\n",
    "# Make sure the column order to the same for both german and english csv files\n",
    "df_german_exploded = df_german_exploded.select('sentence', 'emotion')\n",
    "\n",
    "print(f'Count (filtered): {df_german_exploded.count()}')\n",
    "\n",
    "# Group By for Details & Count\n",
    "df_german_grouped = df_german_exploded.groupBy('emotion').count()\n",
    "\n",
    "# Show Groupings and Respetive Counts\n",
    "print('\\nGrouped & Count by \"emotion\"')\n",
    "df_german_grouped.show(truncate=0)\n",
    "\n",
    "\n",
    "# Save Dataframe to CSV\n",
    "directory_path = 'data/spark_data_parts'\n",
    "df_german_exploded.coalesce(1).write.csv(directory_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "file_pattern = 'part-00000*.csv'\n",
    "file_path = glob.glob(directory_path + '/' + file_pattern)[0]\n",
    "\n",
    "shutil.move(file_path, './data/data_de.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90720f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
