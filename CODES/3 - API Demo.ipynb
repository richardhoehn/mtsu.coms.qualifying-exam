{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7f54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/14 15:23:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:8080\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I am so happy about this news!\n",
      "German: \n",
      "English: I am so happy about this news!\n",
      "German: Ich freue mich sehr über diese Neuigkeiten!\n",
      "23/08/14 15:24:58 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/14 15:24:58 WARN InstanceBuilder$JavaBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "23/08/14 15:24:59 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Aug/2023 15:24:59] \"GET /predict?sentence_en=I%20am%20so%20happy%20about%20this%20news!&sentence_de= HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I would never go to this place again - terrible!\n",
      "German: \n",
      "English: I would never go to this place again - terrible!\n",
      "German: Ich würde nie wieder an diesen Ort gehen - schrecklich!\n",
      "23/08/14 15:25:26 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/14 15:25:26 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Aug/2023 15:25:27] \"GET /predict?sentence_en=I%20would%20never%20go%20to%20this%20place%20again%20-%20terrible!&sentence_de= HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I would never go to this place again - so bad!\n",
      "German: \n",
      "English: I would never go to this place again - so bad!\n",
      "German: Ich würde nie wieder an diesen Ort gehen - so schlecht!\n",
      "23/08/14 15:25:37 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/14 15:25:37 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Aug/2023 15:25:38] \"GET /predict?sentence_en=I%20would%20never%20go%20to%20this%20place%20again%20-%20so%20bad!&sentence_de= HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I would never go to this place again - total junk!\n",
      "German: \n",
      "English: I would never go to this place again - total junk!\n",
      "German: Ich würde nie wieder an diesen Ort gehen - totaler Müll!\n",
      "23/08/14 15:25:48 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/14 15:25:49 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Aug/2023 15:25:49] \"GET /predict?sentence_en=I%20would%20never%20go%20to%20this%20place%20again%20-%20total%20junk!&sentence_de= HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I hate that the vote came in negative\n",
      "German: \n",
      "English: I hate that the vote came in negative\n",
      "German: Ich hasse es, dass die Abstimmung negativ kam\n",
      "23/08/14 15:26:05 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/14 15:26:06 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Aug/2023 15:26:06] \"GET /predict?sentence_en=I%20hate%20that%20the%20vote%20came%20in%20negative&sentence_de= HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I hate that the vote came in negative this time\n",
      "German: \n",
      "English: I hate that the vote came in negative this time\n",
      "German: Ich hasse es, dass die Abstimmung diesmal negativ war\n",
      "23/08/14 15:26:13 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/14 15:26:13 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Aug/2023 15:26:14] \"GET /predict?sentence_en=I%20hate%20that%20the%20vote%20came%20in%20negative%20this%20time&sentence_de= HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: This not a good idea, we should stop.\n",
      "German: \n",
      "English: This not a good idea, we should stop.\n",
      "German: Dies ist keine gute Idee, wir sollten aufhören.\n",
      "23/08/14 15:26:30 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/14 15:26:31 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Aug/2023 15:26:31] \"GET /predict?sentence_en=This%20not%20a%20good%20idea,%20we%20should%20stop.&sentence_de= HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: This is bad idea and we need to stop right now\n",
      "German: \n",
      "English: This is bad idea and we need to stop right now\n",
      "German: Dies ist eine schlechte Idee und wir müssen jetzt aufhören\n",
      "23/08/14 15:26:45 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/14 15:26:45 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Aug/2023 15:26:45] \"GET /predict?sentence_en=This%20is%20bad%20idea%20and%20we%20need%20to%20stop%20right%20now&sentence_de= HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Gosh I hate doing this today.\n",
      "German: \n",
      "English: Gosh I hate doing this today.\n",
      "German: Meine Güte, ich hasse es heute.\n",
      "23/08/14 15:54:41 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/14 15:54:41 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Aug/2023 15:54:42] \"GET /predict?sentence_en=Gosh%20I%20hate%20doing%20this%20today.&sentence_de= HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Setup Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import API Modules \n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import datetime\n",
    "\n",
    "# Import Translator\n",
    "from googletrans import Translator\n",
    "\n",
    "# Impport Tokenizer and Pipeline Tools\n",
    "from transformers import DistilBertTokenizer\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "# Setup Spark Session\n",
    "sc = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"API-Demo\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Add Numerical Label for Emotions\n",
    "emotion_key = {\n",
    "    \"boredom\": 0,\n",
    "    \"love\": 1,\n",
    "    \"relief\": 2,\n",
    "    \"fun\": 3,\n",
    "    \"hate\": 4,\n",
    "    \"neutral\": 5,\n",
    "    \"anger\": 6,\n",
    "    \"happiness\": 7,\n",
    "    \"surprise\": 8,\n",
    "    \"sadness\": 9,\n",
    "    \"worry\": 10,\n",
    "    \"enthusiasm\": 11,\n",
    "    \"empty\": 12,\n",
    "    \"---\": 13\n",
    "}\n",
    "\n",
    "# Initialize the AutoTokenizer\n",
    "# DistilBERT is a compact version of the BERT (Bidirectional Encoder Representations from Transformers) \n",
    "# We are pulling this from Huggingface via the Huggingface transformers\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "# Load Saved Models from the \"2 - ML Training And Testing.ipynb\" file\n",
    "model_en_rfc = PipelineModel.load(\"./models/model_en_rfc.model\")\n",
    "model_en_nb = PipelineModel.load(\"./models/model_en_nb.model\")\n",
    "model_en_lr = PipelineModel.load(\"./models/model_en_lr.model\")\n",
    "model_de_rfc = PipelineModel.load(\"./models/model_de_rfc.model\")\n",
    "model_de_nb = PipelineModel.load(\"./models/model_de_nb.model\")\n",
    "model_de_lr = PipelineModel.load(\"./models/model_de_lr.model\")\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Use the CORS class to enable CORS for the entire app\n",
    "translator = Translator()\n",
    "\n",
    "# Setup Emotion Key Reverse\n",
    "emotions = {v: k for k, v in emotion_key.items()}\n",
    "\n",
    "@app.route('/predict', methods=['GET'])\n",
    "def transform_data():\n",
    "    start_time = datetime.datetime.now()\n",
    "    sentence_en = request.args.get('sentence_en')\n",
    "    sentence_de = request.args.get('sentence_de')\n",
    "    \n",
    "    print(f\"English: {sentence_en}\")\n",
    "    print(f\"German: {sentence_de}\")\n",
    "    \n",
    "    if sentence_en:\n",
    "        sentence_de = translator.translate(sentence_en, dest=\"de\").text\n",
    "    elif sentence_de:\n",
    "        sentence_en = translator.translate(sentence_de, dest=\"en\").text\n",
    "    else:\n",
    "        return jsonify({'error': 'No Sentence provided!'})\n",
    "    \n",
    "    print(f\"English: {sentence_en}\")\n",
    "    print(f\"German: {sentence_de}\")\n",
    "    \n",
    "    words_en = tokenizer.tokenize(sentence_en)\n",
    "    words_de = tokenizer.tokenize(sentence_de)\n",
    "\n",
    "    # Create Englsih & German Dataframe\n",
    "    df_en_api = sc.createDataFrame([(sentence_en, words_en)], [\"sentence\", \"words\"])\n",
    "    df_de_api = sc.createDataFrame([(sentence_de, words_de)], [\"sentence\", \"words\"])\n",
    "    \n",
    "    predictions_en_rfc = model_en_rfc.transform(df_en_api)\n",
    "    predictions_en_nb = model_en_nb.transform(df_en_api)\n",
    "    predictions_en_lr = model_en_lr.transform(df_en_api)\n",
    "    predictions_de_rfc = model_de_rfc.transform(df_de_api)\n",
    "    predictions_de_nb = model_de_nb.transform(df_de_api)\n",
    "    predictions_de_lr = model_de_lr.transform(df_de_api)\n",
    "    \n",
    "    # Get End Time\n",
    "    end_time = datetime.datetime.now()\n",
    "    elapsed_time = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    #Build Response\n",
    "    resp = {\n",
    "        \"sentence\": {\n",
    "            \"english\": sentence_en,\n",
    "            \"german\": sentence_de,\n",
    "        },\n",
    "        \"predictions\": {\n",
    "            \"en_rfc\": emotions.get(predictions_en_rfc.collect()[0][\"prediction\"]),\n",
    "            \"en_nb\":  emotions.get(predictions_en_nb.collect()[0][\"prediction\"]),\n",
    "            \"en_lr\":  emotions.get(predictions_en_lr.collect()[0][\"prediction\"]),\n",
    "            \"de_rfc\": emotions.get(predictions_de_rfc.collect()[0][\"prediction\"]),\n",
    "            \"de_nb\":  emotions.get(predictions_de_nb.collect()[0][\"prediction\"]),\n",
    "            \"de_lr\":  emotions.get(predictions_de_lr.collect()[0][\"prediction\"]),\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"spark\": sc.version,\n",
    "            \"datetime\": {\n",
    "                \"start\": start_time,\n",
    "                \"end\": end_time,\n",
    "                \"elapsedInSeconds\": elapsed_time,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return jsonify(resp)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='127.0.0.1', port=8080) # Make sure we listen on \":8080\" since Julyter run on \":8888\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f0332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
