{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da959ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/11 08:46:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Spark V:  3.3.2\n"
     ]
    }
   ],
   "source": [
    "# Setup Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Get Imports Needed\n",
    "from pyspark.sql.functions import col, udf, regexp_replace, lower\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "# Get Datatypes needed for DataFrame manipulation\n",
    "from pyspark.sql.types import IntegerType, StringType, ArrayType\n",
    "\n",
    "# Other Imports\n",
    "import re  # Import the \"re\" module for regular expressions\n",
    "\n",
    "\n",
    "# Setup Spark Session\n",
    "sc = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"Qualyfing-Exam\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Print Spark Version being run\n",
    "print(\"Spark V: \", sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0a3475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Row Count: 1500\n",
      "German Row Count: 1500\n",
      "English Train Row Count: 1288\n",
      "German Train Row Count: 1281\n",
      "English Extended Train Row Count: 2779\n",
      "German Extended Train Row Count: 2781\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  8.0|   81|\n",
      "|  7.0|  186|\n",
      "|  1.0|  142|\n",
      "|  4.0|   42|\n",
      "| 11.0|   25|\n",
      "| 10.0|  288|\n",
      "|  6.0|    8|\n",
      "|  5.0|  310|\n",
      "|  9.0|  206|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  8.0|  291|\n",
      "|  7.0|  271|\n",
      "|  1.0|  334|\n",
      "|  4.0|   62|\n",
      "| 11.0|  494|\n",
      "| 10.0|  375|\n",
      "|  6.0|  140|\n",
      "|  5.0|  499|\n",
      "|  9.0|  313|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup the Dataframes for Training & Testing\n",
    "# Read the English & German Datasets into Dataframes\n",
    "df_en = sc.read.csv(\"data/pd_en_translated.csv\", header=True, inferSchema=True)\n",
    "df_de = sc.read.csv(\"data/pd_de_translated.csv\", header=True, inferSchema=True)\n",
    "print(f\"English Row Count: {df_en.count()}\")\n",
    "print(f\"German Row Count: {df_de.count()}\")\n",
    "\n",
    "# Add Numerical Label for Emotions\n",
    "emotion_key = {\n",
    "    \"boredom\": 0,\n",
    "    \"love\": 1,\n",
    "    \"relief\": 2,\n",
    "    \"fun\": 3,\n",
    "    \"hate\": 4,\n",
    "    \"neutral\": 5,\n",
    "    \"anger\": 6,\n",
    "    \"happiness\": 7,\n",
    "    \"surprise\": 8,\n",
    "    \"sadness\": 9,\n",
    "    \"worry\": 10,\n",
    "    \"enthusiasm\": 11,\n",
    "    \"empty\": 12,\n",
    "    \"---\": 13\n",
    "}\n",
    "\n",
    "# Create a mapping function to map emotion_en to label\n",
    "def map_emotion(label):\n",
    "    return emotion_key[label]\n",
    "\n",
    "# Add a new column \"label\" to the DataFrame with numerical emotion labels\n",
    "map_emotion_udf = F.udf(map_emotion, IntegerType())\n",
    "df_en = df_en.withColumn(\"label\", map_emotion_udf(\"emotion_en\"))\n",
    "df_de = df_de.withColumn(\"label\", map_emotion_udf(\"emotion_en\"))\n",
    "\n",
    "# Cast the Label to Double\n",
    "df_en = df_en.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "df_de = df_de.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "\n",
    "\n",
    "# Make Sure there are No Rows with NULLs in the sentence columns\n",
    "df_en = df_en.dropna(subset=[\"sentence_en\"])\n",
    "df_en = df_en.dropna(subset=[\"sentence_de\"])\n",
    "\n",
    "df_de = df_de.dropna(subset=[\"sentence_de\"])\n",
    "df_de = df_de.dropna(subset=[\"sentence_en\"])\n",
    "\n",
    "\n",
    "# Function to clean Sentence\n",
    "def clean_sentence(sentence):\n",
    "    sentence = re.sub(r'@\\w+', '', sentence) # Remove mentions (@user)\n",
    "    sentence = re.sub(r'#\\w+', '', sentence) # Remove hashtags (#weekend)\n",
    "    sentence = re.sub(r'https?://\\S+|www\\.\\S+|bit\\.ly/\\S+', '', sentence) # Remove URLs\n",
    "    sentence = re.sub(r\"[^\\w\\s]\", \"\", sentence) # Remove special characters and symbols\n",
    "    sentence = sentence.lower() # Convert to lowercase\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence).strip() # Remove multiple spaces and leading/trailing spaces\n",
    "    sentence = re.sub(r'\\t', ' ', sentence) # Remove tabs\n",
    "    return sentence\n",
    "\n",
    "# Create a User-Defined Function (UDF) to apply the sentence cleaning function to the DataFrame\n",
    "clean_sentence_udf = udf(clean_sentence, StringType())\n",
    "df_en = df_en.withColumn(\"sentence_en\", clean_sentence_udf(\"sentence_en\"))\n",
    "df_en = df_en.withColumn(\"sentence_de\", clean_sentence_udf(\"sentence_de\"))\n",
    "\n",
    "df_de = df_de.withColumn(\"sentence_en\", clean_sentence_udf(\"sentence_en\"))\n",
    "df_de = df_de.withColumn(\"sentence_de\", clean_sentence_udf(\"sentence_de\"))\n",
    "\n",
    "\n",
    "# Split the English and German Dataframes for Training and Testing\n",
    "# We are using a 20/80 Split\n",
    "df_en_train, df_en_test = df_en.randomSplit([0.85, 0.15], seed=2023)\n",
    "df_de_train, df_de_test = df_de.randomSplit([0.85, 0.15], seed=2023)\n",
    "print(f\"English Train Row Count: {df_en_train.count()}\")\n",
    "print(f\"German Train Row Count: {df_de_train.count()}\")\n",
    "\n",
    "\n",
    "# Create the Extended Dataframe wiht Translated Data\n",
    "df_en_train_extended = df_en_train.union(df_de.select(*df_en_train.columns))\n",
    "df_de_train_extended = df_de_train.union(df_en.select(*df_de_train.columns))\n",
    "print(f\"English Extended Train Row Count: {df_en_train_extended.count()}\")\n",
    "print(f\"German Extended Train Row Count: {df_de_train_extended.count()}\")\n",
    "\n",
    "\n",
    "df_en_train.groupBy(\"label\").count().show()\n",
    "df_en_train_extended.groupBy(\"label\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97373240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/11 09:17:45 WARN DAGScheduler: Broadcasting large task binary with size 1449.0 KiB\n",
      "23/08/11 09:17:46 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/08/11 09:17:47 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 1763:>                                                       (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/11 09:17:47 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 1765:>                                                       (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/11 09:17:48 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 1767:>                                                       (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/11 09:17:55 WARN DAGScheduler: Broadcasting large task binary with size 1513.8 KiB\n",
      "23/08/11 09:17:55 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/08/11 09:17:56 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 1868:>                                                       (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/11 09:17:57 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 1870:>                                                       (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/11 09:17:58 WARN DAGScheduler: Broadcasting large task binary with size 7.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed folder: ./models/model_en_nb.model/stages/0_StopWordsRemover_26ba14aeb971/metadata\n",
      "Removed folder: ./models/model_en_nb.model/stages/3_NaiveBayes_3aca16295988/data\n",
      "Removed folder: ./models/model_en_nb.model/stages/3_NaiveBayes_3aca16295988/metadata\n",
      "Removed folder: ./models/model_en_nb.model/stages/1_CountVectorizer_450bf45e4a27/data\n",
      "Removed folder: ./models/model_en_nb.model/stages/1_CountVectorizer_450bf45e4a27/metadata\n",
      "Removed folder: ./models/model_en_nb.model/stages/2_IDF_f91d20a38f2d/data\n",
      "Removed folder: ./models/model_en_nb.model/stages/2_IDF_f91d20a38f2d/metadata\n",
      "Removed folder: ./models/model_en_nb.model/stages/0_StopWordsRemover_26ba14aeb971\n",
      "Removed folder: ./models/model_en_nb.model/stages/3_NaiveBayes_3aca16295988\n",
      "Removed folder: ./models/model_en_nb.model/stages/1_CountVectorizer_450bf45e4a27\n",
      "Removed folder: ./models/model_en_nb.model/stages/2_IDF_f91d20a38f2d\n",
      "Removed folder: ./models/model_en_nb.model/stages\n",
      "Removed folder: ./models/model_en_nb.model/metadata\n",
      "Removed folder: ./models/model_de_nb.model/stages/0_StopWordsRemover_26ba14aeb971/metadata\n",
      "Removed folder: ./models/model_de_nb.model/stages/3_NaiveBayes_3aca16295988/data\n",
      "Removed folder: ./models/model_de_nb.model/stages/3_NaiveBayes_3aca16295988/metadata\n",
      "Removed folder: ./models/model_de_nb.model/stages/1_CountVectorizer_450bf45e4a27/data\n",
      "Removed folder: ./models/model_de_nb.model/stages/1_CountVectorizer_450bf45e4a27/metadata\n",
      "Removed folder: ./models/model_de_nb.model/stages/2_IDF_f91d20a38f2d/data\n",
      "Removed folder: ./models/model_de_nb.model/stages/2_IDF_f91d20a38f2d/metadata\n",
      "Removed folder: ./models/model_de_nb.model/stages/0_StopWordsRemover_26ba14aeb971\n",
      "Removed folder: ./models/model_de_nb.model/stages/3_NaiveBayes_3aca16295988\n",
      "Removed folder: ./models/model_de_nb.model/stages/1_CountVectorizer_450bf45e4a27\n",
      "Removed folder: ./models/model_de_nb.model/stages/2_IDF_f91d20a38f2d\n",
      "Removed folder: ./models/model_de_nb.model/stages\n",
      "Removed folder: ./models/model_de_nb.model/metadata\n",
      "Removed folder: ./models/model_en_rfc.model/stages/1_Word2Vec_1d757f24c6e9/data\n",
      "Removed folder: ./models/model_en_rfc.model/stages/1_Word2Vec_1d757f24c6e9/metadata\n",
      "Removed folder: ./models/model_en_rfc.model/stages/0_StopWordsRemover_26ba14aeb971/metadata\n",
      "Removed folder: ./models/model_en_rfc.model/stages/2_RandomForestClassifier_e4289b9d326b/treesMetadata\n",
      "Removed folder: ./models/model_en_rfc.model/stages/2_RandomForestClassifier_e4289b9d326b/data\n",
      "Removed folder: ./models/model_en_rfc.model/stages/2_RandomForestClassifier_e4289b9d326b/metadata\n",
      "Removed folder: ./models/model_en_rfc.model/stages/1_Word2Vec_1d757f24c6e9\n",
      "Removed folder: ./models/model_en_rfc.model/stages/0_StopWordsRemover_26ba14aeb971\n",
      "Removed folder: ./models/model_en_rfc.model/stages/2_RandomForestClassifier_e4289b9d326b\n",
      "Removed folder: ./models/model_en_rfc.model/stages\n",
      "Removed folder: ./models/model_en_rfc.model/metadata\n",
      "Removed folder: ./models/model_en_lr.model/stages/3_LogisticRegression_35c3b1e14222/data\n",
      "Removed folder: ./models/model_en_lr.model/stages/3_LogisticRegression_35c3b1e14222/metadata\n",
      "Removed folder: ./models/model_en_lr.model/stages/0_StopWordsRemover_26ba14aeb971/metadata\n",
      "Removed folder: ./models/model_en_lr.model/stages/1_CountVectorizer_450bf45e4a27/data\n",
      "Removed folder: ./models/model_en_lr.model/stages/1_CountVectorizer_450bf45e4a27/metadata\n",
      "Removed folder: ./models/model_en_lr.model/stages/2_IDF_f91d20a38f2d/data\n",
      "Removed folder: ./models/model_en_lr.model/stages/2_IDF_f91d20a38f2d/metadata\n",
      "Removed folder: ./models/model_en_lr.model/stages/3_LogisticRegression_35c3b1e14222\n",
      "Removed folder: ./models/model_en_lr.model/stages/0_StopWordsRemover_26ba14aeb971\n",
      "Removed folder: ./models/model_en_lr.model/stages/1_CountVectorizer_450bf45e4a27\n",
      "Removed folder: ./models/model_en_lr.model/stages/2_IDF_f91d20a38f2d\n",
      "Removed folder: ./models/model_en_lr.model/stages\n",
      "Removed folder: ./models/model_en_lr.model/metadata\n",
      "Removed folder: ./models/model_de_lr.model/stages/3_LogisticRegression_35c3b1e14222/data\n",
      "Removed folder: ./models/model_de_lr.model/stages/3_LogisticRegression_35c3b1e14222/metadata\n",
      "Removed folder: ./models/model_de_lr.model/stages/0_StopWordsRemover_26ba14aeb971/metadata\n",
      "Removed folder: ./models/model_de_lr.model/stages/1_CountVectorizer_450bf45e4a27/data\n",
      "Removed folder: ./models/model_de_lr.model/stages/1_CountVectorizer_450bf45e4a27/metadata\n",
      "Removed folder: ./models/model_de_lr.model/stages/2_IDF_f91d20a38f2d/data\n",
      "Removed folder: ./models/model_de_lr.model/stages/2_IDF_f91d20a38f2d/metadata\n",
      "Removed folder: ./models/model_de_lr.model/stages/3_LogisticRegression_35c3b1e14222\n",
      "Removed folder: ./models/model_de_lr.model/stages/0_StopWordsRemover_26ba14aeb971\n",
      "Removed folder: ./models/model_de_lr.model/stages/1_CountVectorizer_450bf45e4a27\n",
      "Removed folder: ./models/model_de_lr.model/stages/2_IDF_f91d20a38f2d\n",
      "Removed folder: ./models/model_de_lr.model/stages\n",
      "Removed folder: ./models/model_de_lr.model/metadata\n",
      "Removed folder: ./models/model_de_rfc.model/stages/1_Word2Vec_1d757f24c6e9/data\n",
      "Removed folder: ./models/model_de_rfc.model/stages/1_Word2Vec_1d757f24c6e9/metadata\n",
      "Removed folder: ./models/model_de_rfc.model/stages/0_StopWordsRemover_26ba14aeb971/metadata\n",
      "Removed folder: ./models/model_de_rfc.model/stages/2_RandomForestClassifier_e4289b9d326b/treesMetadata\n",
      "Removed folder: ./models/model_de_rfc.model/stages/2_RandomForestClassifier_e4289b9d326b/data\n",
      "Removed folder: ./models/model_de_rfc.model/stages/2_RandomForestClassifier_e4289b9d326b/metadata\n",
      "Removed folder: ./models/model_de_rfc.model/stages/1_Word2Vec_1d757f24c6e9\n",
      "Removed folder: ./models/model_de_rfc.model/stages/0_StopWordsRemover_26ba14aeb971\n",
      "Removed folder: ./models/model_de_rfc.model/stages/2_RandomForestClassifier_e4289b9d326b\n",
      "Removed folder: ./models/model_de_rfc.model/stages\n",
      "Removed folder: ./models/model_de_rfc.model/metadata\n",
      "Removed folder: ./models/model_en_nb.model\n",
      "Removed folder: ./models/model_de_nb.model\n",
      "Removed folder: ./models/model_en_rfc.model\n",
      "Removed folder: ./models/model_en_lr.model\n",
      "Removed folder: ./models/model_de_lr.model\n",
      "Removed folder: ./models/model_de_rfc.model\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  8.0|   24|\n",
      "|  7.0|   10|\n",
      "|  1.0|   25|\n",
      "|  4.0|    5|\n",
      "| 11.0|   72|\n",
      "| 10.0|    9|\n",
      "|  6.0|   23|\n",
      "|  5.0|   30|\n",
      "|  9.0|   12|\n",
      "+-----+-----+\n",
      "\n",
      "23/08/11 09:18:05 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "23/08/11 09:18:06 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "23/08/11 09:18:06 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "23/08/11 09:18:07 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "\n",
      "English Dataset\n",
      "Test Accuracy (RFC): 0.2406 with an F1: 0.1991\n",
      "Test Accuracy (NB): 0.0566 with an F1: 0.0692\n",
      "Test Accuracy (LR): 0.3208 with an F1: 0.2368\n",
      "\n",
      "\n",
      "German Dataset\n",
      "Test Accuracy (RFC): 0.2762 with an F1: 0.1831\n",
      "Test Accuracy (NB): 0.0429 with an F1: 0.0431\n",
      "Test Accuracy (LR): 0.3429 with an F1: 0.1757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, Tokenizer, StopWordsRemover, CountVectorizer, IDF, Word2Vec\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Clean Dataframes (becasue of past iterations)\n",
    "df_en_train = df_en_train.select(\"label\", \"sentence_en\", \"sentence_de\")\n",
    "df_en_test = df_en_test.select(\"label\", \"sentence_en\", \"sentence_de\")\n",
    "df_de_train = df_de_train.select(\"label\", \"sentence_en\", \"sentence_de\")\n",
    "df_de_test = df_de_test.select(\"label\", \"sentence_en\", \"sentence_de\")\n",
    "\n",
    "\n",
    "# Initialize the AutoTokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "# Define a UDF to tokenize the text column\n",
    "def tokenize_text(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "tokenize_udf = udf(tokenize_text, ArrayType(StringType()))\n",
    "\n",
    "\n",
    "# Tokenize the text column using the UDF\n",
    "df_en_train = df_en_train.withColumn(\"words\", tokenize_udf(\"sentence_en\"))\n",
    "df_en_test = df_en_test.withColumn(\"words\", tokenize_udf(\"sentence_en\"))\n",
    "\n",
    "df_de_train = df_de_train.withColumn(\"words\", tokenize_udf(\"sentence_de\"))\n",
    "df_de_test = df_de_test.withColumn(\"words\", tokenize_udf(\"sentence_de\"))\n",
    "\n",
    "\n",
    "# Prepare the feature column by applying various transformations\n",
    "stop_words_remover = StopWordsRemover(inputCol=\"words\", \n",
    "                                      outputCol=\"filtered_words\")\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"filtered_words\", \n",
    "                     outputCol=\"raw_features\", \n",
    "                     vocabSize=1000)\n",
    "\n",
    "idf = IDF(inputCol=\"raw_features\", \n",
    "          outputCol=\"features\")\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=100,\n",
    "                    minCount=3,\n",
    "                    inputCol=\"filtered_words\",\n",
    "                    outputCol=\"features\")\n",
    "\n",
    "# Models\n",
    "rfc = RandomForestClassifier(labelCol=\"label\", \n",
    "                             featuresCol=\"features\", \n",
    "                             maxBins=32,\n",
    "                             numTrees=100, \n",
    "                             maxDepth=10)\n",
    "\n",
    "nb = NaiveBayes(labelCol=\"label\", \n",
    "                featuresCol=\"features\", \n",
    "                modelType=\"multinomial\",\n",
    "                smoothing=1.0)\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", \n",
    "                        featuresCol=\"features\", \n",
    "                        regParam=1.0,\n",
    "                        elasticNetParam=0.01,\n",
    "                        maxIter=100)\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline_rfc = Pipeline(stages=[stop_words_remover, word2Vec, rfc ])\n",
    "pipeline_nb  = Pipeline(stages=[stop_words_remover, cv,       idf, nb])\n",
    "pipeline_lr  = Pipeline(stages=[stop_words_remover, cv,       idf, lr])\n",
    "\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "# This is essentially creating the model\n",
    "model_en_rfc = pipeline_rfc.fit(df_en_train)\n",
    "model_en_nb  = pipeline_nb.fit(df_en_train)\n",
    "model_en_lr  = pipeline_lr.fit(df_en_train)\n",
    "model_de_rfc = pipeline_rfc.fit(df_de_train)\n",
    "model_de_nb  = pipeline_nb.fit(df_de_train)\n",
    "model_de_lr  = pipeline_lr.fit(df_de_train)\n",
    "\n",
    "# Save Trained Models to Disk\n",
    "# These will later on be used by the RESTful API\n",
    "\n",
    "# First Cleanup Old Models\n",
    "for root, dirs, files in os.walk(\"./models/\", topdown=False):\n",
    "    for dir_name in dirs:\n",
    "        folder_path = os.path.join(root, dir_name)\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Removed folder: {folder_path}\")\n",
    "\n",
    "model_en_rfc.save(\"./models/model_en_rfc.model\")\n",
    "model_en_nb.save(\"./models/model_en_nb.model\")\n",
    "model_en_lr.save(\"./models/model_en_lr.model\")\n",
    "model_de_rfc.save(\"./models/model_de_rfc.model\")\n",
    "model_de_nb.save(\"./models/model_de_nb.model\")\n",
    "model_de_lr.save(\"./models/model_de_lr.model\")\n",
    "\n",
    "\n",
    "# Make Predictions\n",
    "predictions_en_rfc = model_en_rfc.transform(df_en_test)\n",
    "predictions_en_nb = model_en_nb.transform(df_en_test)\n",
    "predictions_en_lr = model_en_lr.transform(df_en_test)\n",
    "predictions_de_rfc = model_de_rfc.transform(df_de_test)\n",
    "predictions_de_nb = model_de_nb.transform(df_de_test)\n",
    "predictions_de_lr = model_de_lr.transform(df_de_test)\n",
    "\n",
    "\n",
    "# Evaluate the model's performance\n",
    "eval_ac = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "eval_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Process English\n",
    "accuracy_en_rfc = eval_ac.evaluate(predictions_en_rfc)\n",
    "accuracy_en_nb = eval_ac.evaluate(predictions_en_nb)\n",
    "accuracy_en_lr = eval_ac.evaluate(predictions_en_lr)\n",
    "\n",
    "f1_en_rfc = eval_f1.evaluate(predictions_en_rfc)\n",
    "f1_en_nb = eval_f1.evaluate(predictions_en_nb)\n",
    "f1_en_lr = eval_f1.evaluate(predictions_en_lr)\n",
    "\n",
    "# Process German\n",
    "accuracy_de_rfc = eval_ac.evaluate(predictions_de_rfc)\n",
    "accuracy_de_nb = eval_ac.evaluate(predictions_de_nb)\n",
    "accuracy_de_lr = eval_ac.evaluate(predictions_de_lr)\n",
    "\n",
    "f1_de_rfc = eval_f1.evaluate(predictions_de_rfc)\n",
    "f1_de_nb = eval_f1.evaluate(predictions_de_nb)\n",
    "f1_de_lr = eval_f1.evaluate(predictions_de_lr)\n",
    "\n",
    "print()\n",
    "print(\"English Dataset\")\n",
    "print(f\"Test Accuracy (RFC): {accuracy_en_rfc:.4f} with an F1: {f1_en_rfc:.4f}\")\n",
    "print(f\"Test Accuracy (NB): {accuracy_en_nb:.4f} with an F1: {f1_en_nb:.4f}\")\n",
    "print(f\"Test Accuracy (LR): {accuracy_en_lr:.4f} with an F1: {f1_en_lr:.4f}\")\n",
    "print()\n",
    "\n",
    "print()\n",
    "print(\"German Dataset\")\n",
    "print(f\"Test Accuracy (RFC): {accuracy_de_rfc:.4f} with an F1: {f1_de_rfc:.4f}\")\n",
    "print(f\"Test Accuracy (NB): {accuracy_de_nb:.4f} with an F1: {f1_de_nb:.4f}\")\n",
    "print(f\"Test Accuracy (LR): {accuracy_de_lr:.4f} with an F1: {f1_de_lr:.4f}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f42128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE - Labels\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  8.0|   24|\n",
      "|  7.0|   10|\n",
      "|  1.0|   25|\n",
      "|  4.0|    5|\n",
      "| 11.0|   72|\n",
      "| 10.0|    9|\n",
      "|  6.0|   23|\n",
      "|  5.0|   30|\n",
      "|  9.0|   12|\n",
      "+-----+-----+\n",
      "\n",
      "DE - RFC\n",
      "23/08/11 10:09:35 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "23/08/11 10:09:35 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       8.0|   11|\n",
      "|       7.0|    5|\n",
      "|       1.0|   13|\n",
      "|       4.0|    2|\n",
      "|      11.0|  161|\n",
      "|      10.0|    4|\n",
      "|       6.0|    7|\n",
      "|       5.0|    5|\n",
      "|       9.0|    2|\n",
      "+----------+-----+\n",
      "\n",
      "DE - LR\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|      11.0|  209|\n",
      "|       6.0|    1|\n",
      "+----------+-----+\n",
      "\n",
      "DE - NB\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       8.0|   47|\n",
      "|       0.0|   34|\n",
      "|       7.0|   20|\n",
      "|       1.0|    5|\n",
      "|       4.0|   16|\n",
      "|       3.0|   16|\n",
      "|       2.0|   28|\n",
      "|       6.0|   20|\n",
      "|       5.0|   24|\n",
      "+----------+-----+\n",
      "\n",
      "EN - Labels\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  8.0|   10|\n",
      "|  7.0|   39|\n",
      "|  1.0|   26|\n",
      "|  4.0|    9|\n",
      "| 11.0|    3|\n",
      "| 10.0|   46|\n",
      "|  5.0|   50|\n",
      "|  9.0|   29|\n",
      "+-----+-----+\n",
      "\n",
      "EN - RFC\n",
      "23/08/11 10:09:36 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "23/08/11 10:09:36 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       8.0|    1|\n",
      "|       7.0|   17|\n",
      "|       1.0|   11|\n",
      "|      10.0|   63|\n",
      "|       5.0|  101|\n",
      "|       9.0|   19|\n",
      "+----------+-----+\n",
      "\n",
      "EN - LR\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       7.0|    5|\n",
      "|       1.0|    3|\n",
      "|      10.0|   50|\n",
      "|       5.0|  152|\n",
      "|       9.0|    2|\n",
      "+----------+-----+\n",
      "\n",
      "EN - NB\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       8.0|    9|\n",
      "|       0.0|   25|\n",
      "|       7.0|   44|\n",
      "|       1.0|    8|\n",
      "|       4.0|   31|\n",
      "|       3.0|    5|\n",
      "|       2.0|   33|\n",
      "|       6.0|   36|\n",
      "|       5.0|   21|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DE - Labels\")\n",
    "predictions_de_rfc.groupBy(\"label\").count().show()\n",
    "\n",
    "print(\"DE - RFC\")\n",
    "predictions_de_rfc.groupBy(\"prediction\").count().show()\n",
    "\n",
    "print(\"DE - LR\")\n",
    "predictions_de_lr.groupBy(\"prediction\").count().show()\n",
    "\n",
    "print(\"DE - NB\")\n",
    "predictions_de_nb.groupBy(\"prediction\").count().show()\n",
    "\n",
    "print(\"EN - Labels\")\n",
    "predictions_en_rfc.groupBy(\"label\").count().show()\n",
    "\n",
    "print(\"EN - RFC\")\n",
    "predictions_en_rfc.groupBy(\"prediction\").count().show()\n",
    "\n",
    "print(\"EN - LR\")\n",
    "predictions_en_lr.groupBy(\"prediction\").count().show()\n",
    "\n",
    "print(\"EN - NB\")\n",
    "predictions_en_nb.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5d7f54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:8080\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I am so happy\n",
      "German: ich bin so glücklich\n",
      "23/08/11 09:31:01 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:31:02 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:31:02] \"GET /predict?sentence_en=I%20am%20so%20happy HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: This is not good\n",
      "German: Das ist nicht gut\n",
      "23/08/11 09:31:13 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:31:14 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:31:14] \"GET /predict?sentence_en=This%20is%20not%20good HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: This is not bad\n",
      "German: Das ist nicht schlecht\n",
      "23/08/11 09:31:28 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:31:29 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:31:29] \"GET /predict?sentence_en=This%20is%20not%20bad HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: This is not bad lets do it\n",
      "German: Das ist nicht schlecht, lass es uns tun\n",
      "23/08/11 09:31:47 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:31:47 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:31:48] \"GET /predict?sentence_en=This%20is%20not%20bad%20lets%20do%20it HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: This is bad lets do it\n",
      "German: Das ist schlecht, lass es uns tun\n",
      "23/08/11 09:32:03 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:32:03 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:32:03] \"GET /predict?sentence_en=This%20is%20bad%20lets%20do%20it HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I would love to participate\n",
      "German: Ich würde gerne teilnehmen\n",
      "23/08/11 09:32:19 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:32:20 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:32:20] \"GET /predict?sentence_en=I%20would%20love%20to%20participate HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I would love\n",
      "German: Ich würde lieben\n",
      "23/08/11 09:32:33 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:32:33 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:32:33] \"GET /predict?sentence_en=I%20would%20love HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Wie intelligent ist künstliche Intelligenz\n",
      "German: Wie intelligent ist künstliche Intelligenz\n",
      "23/08/11 09:33:23 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:33:24 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:33:24] \"GET /predict?sentence_en=Wie%20intelligent%20ist%20künstliche%20Intelligenz HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: How smart is AI\n",
      "German: Wie schlau ist KI\n",
      "23/08/11 09:33:36 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:33:36 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:33:36] \"GET /predict?sentence_en=How%20smart%20is%20AI HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: How intelligent is artificial intelligence?\n",
      "German: Wie intelligent ist künstliche Intelligenz?\n",
      "23/08/11 09:34:05 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:34:06 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:34:06] \"GET /predict?sentence_en=How%20intelligent%20is%20artificial%20intelligence? HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: How intelligent are you \n",
      "German: Wie intelligent bist du\n",
      "23/08/11 09:34:22 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:34:23 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:34:23] \"GET /predict?sentence_en=How%20intelligent%20are%20you%20 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I am not looking forward to this\n",
      "German: Ich freue mich nicht darauf\n",
      "23/08/11 09:34:44 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "23/08/11 09:34:45 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Aug/2023 09:34:45] \"GET /predict?sentence_en=I%20am%20not%20looking%20forward%20to%20this HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Setup API \n",
    "from flask import Flask, request, jsonify\n",
    "from googletrans import Translator\n",
    "\n",
    "# Setup\n",
    "from transformers import DistilBertTokenizer\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "\n",
    "# Initialize the AutoTokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "\n",
    "# Load Saved Models\n",
    "model_en_rfc = PipelineModel.load(\"./models/model_en_rfc.model\")\n",
    "model_en_nb = PipelineModel.load(\"./models/model_en_nb.model\")\n",
    "model_en_lr = PipelineModel.load(\"./models/model_en_lr.model\")\n",
    "model_de_rfc = PipelineModel.load(\"./models/model_de_rfc.model\")\n",
    "model_de_nb = PipelineModel.load(\"./models/model_de_nb.model\")\n",
    "model_de_lr = PipelineModel.load(\"./models/model_de_lr.model\")\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "translator = Translator()\n",
    "\n",
    "# Setup Emotion Key Reverse\n",
    "emotions = {v: k for k, v in emotion_key.items()}\n",
    "\n",
    "@app.route('/predict', methods=['GET'])\n",
    "def transform_data():\n",
    "    sentence_en = request.args.get('sentence_en')\n",
    "    \n",
    "    if not sentence_en:\n",
    "        return jsonify({'error': 'No Sentence (EN) provided!'})\n",
    "    \n",
    "    sentence_de = translator.translate(sentence_en, dest=\"de\").text\n",
    "    print(f\"English: {sentence_en}\")\n",
    "    print(f\"German: {sentence_de}\")\n",
    "    \n",
    "    words_en = tokenizer.tokenize(sentence_en)\n",
    "    words_de = tokenizer.tokenize(sentence_de)\n",
    "\n",
    "    # Create Englsih & German Dataframe\n",
    "    df_en_api = sc.createDataFrame([(sentence_en, words_en)], [\"sentence\", \"words\"])\n",
    "    df_de_api = sc.createDataFrame([(sentence_de, words_de)], [\"sentence\", \"words\"])\n",
    "    \n",
    "    predictions_en_rfc = model_en_rfc.transform(df_en_api)\n",
    "    predictions_en_nb = model_en_nb.transform(df_en_api)\n",
    "    predictions_en_lr = model_en_lr.transform(df_en_api)\n",
    "    predictions_de_rfc = model_de_rfc.transform(df_de_api)\n",
    "    predictions_de_nb = model_de_nb.transform(df_de_api)\n",
    "    predictions_de_lr = model_de_lr.transform(df_de_api)\n",
    "    \n",
    "    #Build Response\n",
    "    resp = {\n",
    "        \"sentence\": {\n",
    "            \"english\":sentence_en,\n",
    "            \"german\":sentence_de,\n",
    "        },\n",
    "        \"predictions\": {\n",
    "            \"en_rfc\": emotions.get(predictions_en_rfc.collect()[0][\"prediction\"]),\n",
    "            \"en_nb\":  emotions.get(predictions_en_nb.collect()[0][\"prediction\"]),\n",
    "            \"en_lr\":  emotions.get(predictions_en_lr.collect()[0][\"prediction\"]),\n",
    "            \"de_rfc\": emotions.get(predictions_de_rfc.collect()[0][\"prediction\"]),\n",
    "            \"de_nb\":  emotions.get(predictions_de_nb.collect()[0][\"prediction\"]),\n",
    "            \"de_lr\":  emotions.get(predictions_de_lr.collect()[0][\"prediction\"]),\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return jsonify(resp)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='127.0.0.1', port=8080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26866261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
